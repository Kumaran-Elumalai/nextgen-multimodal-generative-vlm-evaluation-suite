# ğŸ§ ğŸ“¸ Visionâ€“Language Models (VLMs) for Visual Question Answering

Modern AI systems are increasingly **multimodal**, capable of processing and generating information from diverse sources such as **images and text**.  
This project focuses on **Visionâ€“Language Models (VLMs)** designed to combine visual and textual understanding for:

- **Visual Question Answering (VQA)**
- **Descriptive image generation and captioning**

## ğŸš€ Overview

This repository demonstrates practical multimodal AI development by implementing two advanced VLMs:

### ğŸ”¹ ViLT â€“ Vision-and-Language Transformer
- Lightweight and optimized for CPU-friendly deployment  
- Fast inference  
- Ideal for **single-word or short-answer VQA**

### ğŸ”¹ SmolVLM â€“ Small Vision-Language Model
- Generates multi-sentence, descriptive responses  
- Great for **detailed image understanding and explanation**

## ğŸ¯ Project Goals

This project aims to provide:

- âœ”ï¸ **End-to-end multimodal pipelines** for image + text reasoning  
- âœ”ï¸ **Efficient CPU-based inference** without requiring GPUs  
- âœ”ï¸ **Clean, professional, interactive AI demos** showcasing real-world VQA and multimodal capabilities  

## ğŸ“ Repository Structure

```
nextgen-multimodal-generative-vlm-evaluation-suite/
â”‚â”€â”€ vilt_vqa/
â”‚   â””â”€â”€ vilt_app.py
â”‚â”€â”€ smolvlm_vqa/
â”‚   â””â”€â”€ smolvlm_app.py
â”‚â”€â”€ assets/
â”‚   â””â”€â”€ sample_images/
â”‚â”€â”€ README.md
â”‚â”€â”€ requirements.txt
```
## ğŸ§  Features

- **Two Multimodal Pipelines:**  
  ViLT (classification-style VQA) and SmolVLM (generative, descriptive answers)

- **Interactive Gradio Interfaces:**  
  Upload an image and get a professional, descriptive answer

- **CPU-Friendly Implementation:**  
  Optimized for environments without GPU

## ğŸ”§ Technical Highlights

### ğŸ”¹ Visionâ€“Language Processing
- **ViLT:** Uses attention-based fusion between image patches and text tokens  
- **SmolVLM:** Combines a Vision Transformer encoder with an LLM decoder for generative outputs

### ğŸ”¹ Prompt Engineering
- Designed to produce descriptive, multi-sentence answers  
- Formatting ensures structured and readable responses

### ğŸ”¹ Inference Optimizations
- Image resizing and normalization  
- Controlled token generation (48â€“60 tokens) to balance latency and richness

### ğŸ”¹ Why These Models?
- **ViLT â†’** Efficient, lightweight transformer ideal for fact-based VQA  
- **SmolVLM â†’** Produces rich, detailed multi-sentence explanations

## ğŸš€ Usage Instructions
- Run ViLT App
```
cd vilt_vqa
python vilt_app.py
```

- Run SmolVLM App
```
cd smolvlm_vqa
python smolvlm_app.py
```
#### A Gradio interface will open in your browser automatically.
